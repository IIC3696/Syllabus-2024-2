{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6a8555-88f6-4132-bce4-6ab7d46d1718",
   "metadata": {},
   "source": [
    "# Clasificando temas de papers \n",
    "\n",
    "En este notebook vamos a tomar una base de datos de papers, y los vamos a clasificar. Vamos a comparar dos enfoques, uno que toma solo las palabras de los papers, y otro que incorpora GNNs para usar la información de que papers citan a cuales otros en la predicción. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd676d-651a-45d9-aa3d-739eb0926b76",
   "metadata": {},
   "source": [
    "## Datos: Cora cites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed276855-02ff-4d99-a618-d6ab6ac0fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ab9493-f980-4079-825d-f7992540fcf6",
   "metadata": {},
   "source": [
    "Este dataset contiene dos archivos. El primero es una base de datos de papers que citan a otros papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "804758dd-da83-4ca8-9284-37e79c201e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>103482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>103515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>1050679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>1103960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>853116</td>\n",
       "      <td>19621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>853116</td>\n",
       "      <td>853155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>853118</td>\n",
       "      <td>1140289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>853155</td>\n",
       "      <td>853118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>954315</td>\n",
       "      <td>1155073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5429 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target   source\n",
       "0         35     1033\n",
       "1         35   103482\n",
       "2         35   103515\n",
       "3         35  1050679\n",
       "4         35  1103960\n",
       "...      ...      ...\n",
       "5424  853116    19621\n",
       "5425  853116   853155\n",
       "5426  853118  1140289\n",
       "5427  853155   853118\n",
       "5428  954315  1155073\n",
       "\n",
       "[5429 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citas = pd.read_csv('cora/cora.cites',sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"target\", \"source\"])\n",
    "\n",
    "citas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c2b312-3525-4220-8aad-dc2dbc71b07c",
   "metadata": {},
   "source": [
    "El segundo archivo contiene informacién de muchas palabras (términos) asociadas a cada paper, y además una categoría. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75418cc1-ffb1-463f-897c-e70cc4f593c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>word_0</th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>word_6</th>\n",
       "      <th>word_7</th>\n",
       "      <th>word_8</th>\n",
       "      <th>...</th>\n",
       "      <th>word_1424</th>\n",
       "      <th>word_1425</th>\n",
       "      <th>word_1426</th>\n",
       "      <th>word_1427</th>\n",
       "      <th>word_1428</th>\n",
       "      <th>word_1429</th>\n",
       "      <th>word_1430</th>\n",
       "      <th>word_1431</th>\n",
       "      <th>word_1432</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1061127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rule_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1106406</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>1128975</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>1128977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>1128978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>117328</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Case_Based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>24043</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2708 rows × 1435 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      paper_id  word_0  word_1  word_2  word_3  word_4  word_5  word_6  \\\n",
       "0        31336       0       0       0       0       0       0       0   \n",
       "1      1061127       0       0       0       0       0       0       0   \n",
       "2      1106406       0       0       0       0       0       0       0   \n",
       "3        13195       0       0       0       0       0       0       0   \n",
       "4        37879       0       0       0       0       0       0       0   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "2703   1128975       0       0       0       0       0       0       0   \n",
       "2704   1128977       0       0       0       0       0       0       0   \n",
       "2705   1128978       0       0       0       0       0       0       0   \n",
       "2706    117328       0       0       0       0       1       0       0   \n",
       "2707     24043       0       0       0       0       0       0       0   \n",
       "\n",
       "      word_7  word_8  ...  word_1424  word_1425  word_1426  word_1427  \\\n",
       "0          0       0  ...          0          0          1          0   \n",
       "1          0       0  ...          0          1          0          0   \n",
       "2          0       0  ...          0          0          0          0   \n",
       "3          0       0  ...          0          0          0          0   \n",
       "4          0       0  ...          0          0          0          0   \n",
       "...      ...     ...  ...        ...        ...        ...        ...   \n",
       "2703       0       0  ...          0          0          0          0   \n",
       "2704       0       0  ...          0          0          0          0   \n",
       "2705       0       0  ...          0          0          0          0   \n",
       "2706       0       0  ...          0          0          0          0   \n",
       "2707       0       0  ...          0          0          0          0   \n",
       "\n",
       "      word_1428  word_1429  word_1430  word_1431  word_1432  \\\n",
       "0             0          0          0          0          0   \n",
       "1             0          0          0          0          0   \n",
       "2             0          0          0          0          0   \n",
       "3             0          0          0          0          0   \n",
       "4             0          0          0          0          0   \n",
       "...         ...        ...        ...        ...        ...   \n",
       "2703          0          0          0          0          0   \n",
       "2704          0          0          0          0          0   \n",
       "2705          0          0          0          0          0   \n",
       "2706          0          0          0          0          0   \n",
       "2707          0          0          0          0          0   \n",
       "\n",
       "                     subject  \n",
       "0            Neural_Networks  \n",
       "1              Rule_Learning  \n",
       "2     Reinforcement_Learning  \n",
       "3     Reinforcement_Learning  \n",
       "4      Probabilistic_Methods  \n",
       "...                      ...  \n",
       "2703      Genetic_Algorithms  \n",
       "2704      Genetic_Algorithms  \n",
       "2705      Genetic_Algorithms  \n",
       "2706              Case_Based  \n",
       "2707         Neural_Networks  \n",
       "\n",
       "[2708 rows x 1435 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###informacion de los papers de acuerdo a loas palabras que mencionan, junto a su paper id y el tema general\n",
    "\n",
    "column_names = [\"paper_id\"] + [f\"word_{idx}\" for idx in range(1433)] + [\"subject\"]\n",
    "papers = pd.read_csv(\n",
    "    'cora/cora.content', sep=\"\\t\", names=column_names,\n",
    ")\n",
    "papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d52e0558-60ee-4e4f-8849-38c768c0a312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject\n",
      "Neural_Networks           818\n",
      "Probabilistic_Methods     426\n",
      "Genetic_Algorithms        418\n",
      "Theory                    351\n",
      "Case_Based                298\n",
      "Reinforcement_Learning    217\n",
      "Rule_Learning             180\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(papers.subject.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aac4a2-3500-490c-a3b7-a085e0900cd7",
   "metadata": {},
   "source": [
    "### 1. Preprocesamiento\n",
    "\n",
    "Vamos a pasar estos subjects a números, y armar los paper_id para que sean consecutivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad17003d-a930-4844-9690-e3ba5852db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_values = sorted(papers[\"subject\"].unique())\n",
    "class_idx = {name: id for id, name in enumerate(class_values)}\n",
    "paper_idx = {name: idx for idx, name in enumerate(sorted(papers[\"paper_id\"].unique()))}\n",
    "\n",
    "papers[\"paper_id\"] = papers[\"paper_id\"].apply(lambda name: paper_idx[name])\n",
    "citas[\"source\"] = citas[\"source\"].apply(lambda name: paper_idx[name])\n",
    "citas[\"target\"] = citas[\"target\"].apply(lambda name: paper_idx[name])\n",
    "papers[\"subject\"] = papers[\"subject\"].apply(lambda value: class_idx[value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050b0d0c-31a0-4351-9ff3-0390dc6588f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>1873</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>1873</td>\n",
       "      <td>1876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>1874</td>\n",
       "      <td>2586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>1876</td>\n",
       "      <td>1874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>1897</td>\n",
       "      <td>2707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5429 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target  source\n",
       "0          0      21\n",
       "1          0     905\n",
       "2          0     906\n",
       "3          0    1909\n",
       "4          0    1940\n",
       "...      ...     ...\n",
       "5424    1873     328\n",
       "5425    1873    1876\n",
       "5426    1874    2586\n",
       "5427    1876    1874\n",
       "5428    1897    2707\n",
       "\n",
       "[5429 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e7186b7-f3d1-406d-9774-7f049c2e92f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject\n",
      "2    818\n",
      "3    426\n",
      "1    418\n",
      "6    351\n",
      "0    298\n",
      "4    217\n",
      "5    180\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(papers.subject.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e671a7-a87a-46f4-9a1d-29446294b4a4",
   "metadata": {},
   "source": [
    "### 2. Sets de training y test\n",
    "Lo último antes de empezar: dividir en dos este dataset (y tratar que nos queden bien balanceados los subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1eaf7c7-4b5e-41a7-92b3-1e3c27256c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero sacamos un 50% de nodos de cada subject\n",
    "train_data, test_data = [], []\n",
    "\n",
    "for nombres, datos_agrupados in papers.groupby(\"subject\"):\n",
    "    random_selection = np.random.rand(len(datos_agrupados.index)) <= 0.5\n",
    "    train_data.append(datos_agrupados[random_selection])\n",
    "    test_data.append(datos_agrupados[~random_selection])\n",
    "train_data = pd.concat(train_data)\n",
    "test_data = pd.concat(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96621675-c48a-4145-a005-85c80ee891b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>word_0</th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>word_6</th>\n",
       "      <th>word_7</th>\n",
       "      <th>word_8</th>\n",
       "      <th>...</th>\n",
       "      <th>word_1424</th>\n",
       "      <th>word_1425</th>\n",
       "      <th>word_1426</th>\n",
       "      <th>word_1427</th>\n",
       "      <th>word_1428</th>\n",
       "      <th>word_1429</th>\n",
       "      <th>word_1430</th>\n",
       "      <th>word_1431</th>\n",
       "      <th>word_1432</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1237</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2660</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>406</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>593</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>1857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>1082</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1377 rows × 1435 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      paper_id  word_0  word_1  word_2  word_3  word_4  word_5  word_6  \\\n",
       "13        1233       0       0       0       0       0       0       0   \n",
       "30         771       0       0       0       0       1       0       0   \n",
       "32         888       0       0       0       0       0       0       0   \n",
       "47        1237       0       0       0       0       0       0       0   \n",
       "50        2660       1       0       1       0       0       0       0   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "2653       406       0       0       0       0       0       0       0   \n",
       "2675       593       0       0       0       0       0       0       0   \n",
       "2685       900       0       0       0       0       0       0       0   \n",
       "2694      1857       0       0       0       0       0       0       0   \n",
       "2696      1082       0       0       0       0       0       0       0   \n",
       "\n",
       "      word_7  word_8  ...  word_1424  word_1425  word_1426  word_1427  \\\n",
       "13         0       0  ...          0          0          0          0   \n",
       "30         0       0  ...          0          0          0          0   \n",
       "32         0       0  ...          0          0          0          0   \n",
       "47         0       0  ...          0          0          0          0   \n",
       "50         0       0  ...          0          0          0          0   \n",
       "...      ...     ...  ...        ...        ...        ...        ...   \n",
       "2653       0       0  ...          0          0          0          0   \n",
       "2675       0       0  ...          0          0          0          0   \n",
       "2685       0       0  ...          0          0          0          0   \n",
       "2694       0       0  ...          0          0          1          0   \n",
       "2696       0       0  ...          0          0          0          0   \n",
       "\n",
       "      word_1428  word_1429  word_1430  word_1431  word_1432  subject  \n",
       "13            0          0          0          0          0        0  \n",
       "30            0          0          0          0          0        0  \n",
       "32            0          0          0          0          0        0  \n",
       "47            0          0          0          0          0        0  \n",
       "50            0          0          0          0          0        0  \n",
       "...         ...        ...        ...        ...        ...      ...  \n",
       "2653          0          0          0          0          0        6  \n",
       "2675          0          0          0          0          0        6  \n",
       "2685          0          0          0          0          0        6  \n",
       "2694          0          0          0          0          0        6  \n",
       "2696          0          0          0          0          0        6  \n",
       "\n",
       "[1377 rows x 1435 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ac831-2ce4-4f42-b192-2169dfb3775f",
   "metadata": {},
   "source": [
    "Nuestra tarea consiste en predecir la línea \"subject\" (el tema del paper), basándonos por ahora solo en el vector de ocurrencias de palabras. Con esto, dividimos el set de training y test en una matriz x y un vector y con los subjects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db45646e-38bf-4442-8531-cea2f84c7463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y luego algunas cosas que se necesitan    \n",
    "feature_names = list(set(papers.columns) - {\"paper_id\", \"subject\"})\n",
    "num_features = len(feature_names)\n",
    "num_classes = len(class_idx)\n",
    "\n",
    "# A torch le gustan los arreglos numpy\n",
    "x_train = train_data[feature_names].to_numpy()\n",
    "x_test = test_data[feature_names].to_numpy()\n",
    "\n",
    "y_train = train_data[\"subject\"].to_numpy()\n",
    "y_test = test_data[\"subject\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ff5129c-5832-4a83-b93c-a493d70a271e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([0, 0, 0, ..., 6, 6, 6]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07809fe-213f-4849-8c6d-436420419cfc",
   "metadata": {},
   "source": [
    "## Primer clasificador: una red neuronal simple.\n",
    "\n",
    "Vamos a conectar un par de capas que corresponden a multi-layered perceptrons (MLP), y ver como aprenden los subjects de los papers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d8d2b4b-6823-4bfc-9a57-aab70ec4a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b02687-96f1-4cdb-85fb-0df22065755c",
   "metadata": {},
   "source": [
    "### Datos para entrenar en batches\n",
    "\n",
    "Lo primero es crear dataset y dataloader para entrenar en batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "985cf4d7-5044-40b7-a8b2-54a77fb65e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.y[idx], dtype=torch.long)\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "51b7ecdd-70bd-43c2-a428-9923390ebe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_dataset = CustomDataset(x_test, y_test)\n",
    "test_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69c28a3-bee7-49c5-9799-4fb6323952f7",
   "metadata": {},
   "source": [
    "Definir la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "305faad4-a5c0-4ad6-a3bb-2cf8fdbbb56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_MLP(hidden_layers, dropout_rate, name=None):\n",
    "    model = nn.Sequential()\n",
    "    num_layer = 0\n",
    "\n",
    "    for layer in hidden_layers:\n",
    "        num_layer +=1\n",
    "        neurons_in = layer[0]\n",
    "        neurons_out = layer[1]\n",
    "        \n",
    "        model.add_module(\"batchnorm\"+str(num_layer), nn.BatchNorm1d(neurons_in))\n",
    "        model.add_module(\"dropout\"+str(num_layer), nn.Dropout(dropout_rate))\n",
    "        model.add_module(\"dense\"+str(num_layer), nn.Linear(neurons_in, neurons_out))\n",
    "        model.add_module(\"activacion\"+str(num_layer), nn.GELU())\n",
    "    \n",
    "    return(model)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47d5742e-35f6-49f9-bff2-f66ae1722fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, input_features, hidden_layer_neurons=32, dropout_rate=0.5, normalize=True):\n",
    "        super(BaseClassifier, self).__init__()\n",
    "\n",
    "        self.preprocessor = create_MLP([[input_features,hidden_layer_neurons],[hidden_layer_neurons,hidden_layer_neurons]], dropout_rate)\n",
    "        self.layer1 = create_MLP([[hidden_layer_neurons,hidden_layer_neurons],[hidden_layer_neurons,hidden_layer_neurons]], dropout_rate)\n",
    "        self.layer2 = create_MLP([[hidden_layer_neurons,hidden_layer_neurons],[hidden_layer_neurons,hidden_layer_neurons]], dropout_rate)\n",
    "        self.layer3 = create_MLP([[hidden_layer_neurons,hidden_layer_neurons],[hidden_layer_neurons,hidden_layer_neurons]], dropout_rate)\n",
    "        self.classifier = nn.Linear(hidden_layer_neurons, num_classes)\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        i = self.preprocessor(input_features)\n",
    "        \n",
    "        c1 = self.layer1(i)\n",
    "        s1 = c1 + i  # Skip connection\n",
    "\n",
    "        c2 = self.layer2(s1)\n",
    "        s2 = c2 + s1  # Skip connection\n",
    "\n",
    "        c3 = self.layer3(s2)\n",
    "        s3 = c3 + s2  # Skip connection\n",
    "\n",
    "        return self.classifier(s3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67780422-4fcf-4d8b-8e23-70ab8c35e464",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8e3d0019-19a4-49f8-9402-092ad0c443d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseClassifier(\n",
      "  (preprocessor): Sequential(\n",
      "    (batchnorm1): BatchNorm1d(1433, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dropout1): Dropout(p=0.5, inplace=False)\n",
      "    (dense1): Linear(in_features=1433, out_features=32, bias=True)\n",
      "    (activacion1): GELU(approximate='none')\n",
      "    (batchnorm2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dropout2): Dropout(p=0.5, inplace=False)\n",
      "    (dense2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activacion2): GELU(approximate='none')\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (batchnorm1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dropout1): Dropout(p=0.5, inplace=False)\n",
      "    (dense1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activacion1): GELU(approximate='none')\n",
      "    (batchnorm2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dropout2): Dropout(p=0.5, inplace=False)\n",
      "    (dense2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activacion2): GELU(approximate='none')\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (batchnorm1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dropout1): Dropout(p=0.5, inplace=False)\n",
      "    (dense1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activacion1): GELU(approximate='none')\n",
      "    (batchnorm2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dropout2): Dropout(p=0.5, inplace=False)\n",
      "    (dense2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activacion2): GELU(approximate='none')\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (batchnorm1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dropout1): Dropout(p=0.5, inplace=False)\n",
      "    (dense1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activacion1): GELU(approximate='none')\n",
      "    (batchnorm2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dropout2): Dropout(p=0.5, inplace=False)\n",
      "    (dense2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activacion2): GELU(approximate='none')\n",
      "  )\n",
      "  (classifier): Linear(in_features=32, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "BASE = BaseClassifier(\n",
    "    num_classes=num_classes,\n",
    "    input_features = num_features\n",
    ")\n",
    "\n",
    "print(BASE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(BASE.parameters(), lr=0.01)\n",
    "num_epochs = 300\n",
    "\n",
    "def calculate_accuracy(output, target):\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    correct = torch.sum(predicted == target).item() \n",
    "    return correct / len(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7ff18f55-edb7-4eb6-950d-68284380b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(model, criterion, optimizer, dataloader, num_epochs):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        \n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute loss and accuracy\n",
    "            running_loss += loss.item()\n",
    "            running_accuracy += calculate_accuracy(outputs, labels)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        epoch_accuracy = running_accuracy / len(dataloader)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af1c0801-0239-4834-a030-fc3e01a44aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 1.9116, Accuracy: 0.2703\n",
      "Epoch [2/300], Loss: 1.7060, Accuracy: 0.3779\n",
      "Epoch [3/300], Loss: 1.4533, Accuracy: 0.4767\n",
      "Epoch [4/300], Loss: 1.1819, Accuracy: 0.5908\n",
      "Epoch [5/300], Loss: 1.1055, Accuracy: 0.6076\n",
      "Epoch [6/300], Loss: 0.9578, Accuracy: 0.6512\n",
      "Epoch [7/300], Loss: 0.8918, Accuracy: 0.7006\n",
      "Epoch [8/300], Loss: 0.8592, Accuracy: 0.6984\n",
      "Epoch [9/300], Loss: 0.8026, Accuracy: 0.7376\n",
      "Epoch [10/300], Loss: 0.7829, Accuracy: 0.7340\n",
      "Epoch [11/300], Loss: 0.7865, Accuracy: 0.7406\n",
      "Epoch [12/300], Loss: 0.7527, Accuracy: 0.7384\n",
      "Epoch [13/300], Loss: 0.7056, Accuracy: 0.7689\n",
      "Epoch [14/300], Loss: 0.6875, Accuracy: 0.7573\n",
      "Epoch [15/300], Loss: 0.6875, Accuracy: 0.7703\n",
      "Epoch [16/300], Loss: 0.6542, Accuracy: 0.7674\n",
      "Epoch [17/300], Loss: 0.6820, Accuracy: 0.7776\n",
      "Epoch [18/300], Loss: 0.6798, Accuracy: 0.7485\n",
      "Epoch [19/300], Loss: 0.6421, Accuracy: 0.7849\n",
      "Epoch [20/300], Loss: 0.6460, Accuracy: 0.7696\n",
      "Epoch [21/300], Loss: 0.6422, Accuracy: 0.7849\n",
      "Epoch [22/300], Loss: 0.6468, Accuracy: 0.7798\n",
      "Epoch [23/300], Loss: 0.6218, Accuracy: 0.7820\n",
      "Epoch [24/300], Loss: 0.5982, Accuracy: 0.7914\n",
      "Epoch [25/300], Loss: 0.6149, Accuracy: 0.7994\n",
      "Epoch [26/300], Loss: 0.6107, Accuracy: 0.7987\n",
      "Epoch [27/300], Loss: 0.5572, Accuracy: 0.8132\n",
      "Epoch [28/300], Loss: 0.6349, Accuracy: 0.7900\n",
      "Epoch [29/300], Loss: 0.6041, Accuracy: 0.7922\n",
      "Epoch [30/300], Loss: 0.6405, Accuracy: 0.7805\n",
      "Epoch [31/300], Loss: 0.5757, Accuracy: 0.8023\n",
      "Epoch [32/300], Loss: 0.5886, Accuracy: 0.7987\n",
      "Epoch [33/300], Loss: 0.5400, Accuracy: 0.8285\n",
      "Epoch [34/300], Loss: 0.5481, Accuracy: 0.7980\n",
      "Epoch [35/300], Loss: 0.5616, Accuracy: 0.7994\n",
      "Epoch [36/300], Loss: 0.5544, Accuracy: 0.8067\n",
      "Epoch [37/300], Loss: 0.5802, Accuracy: 0.7994\n",
      "Epoch [38/300], Loss: 0.5998, Accuracy: 0.7842\n",
      "Epoch [39/300], Loss: 0.5981, Accuracy: 0.7907\n",
      "Epoch [40/300], Loss: 0.5799, Accuracy: 0.7965\n",
      "Epoch [41/300], Loss: 0.5713, Accuracy: 0.7922\n",
      "Epoch [42/300], Loss: 0.5620, Accuracy: 0.7987\n",
      "Epoch [43/300], Loss: 0.5689, Accuracy: 0.7914\n",
      "Epoch [44/300], Loss: 0.5435, Accuracy: 0.7943\n",
      "Epoch [45/300], Loss: 0.5307, Accuracy: 0.8147\n",
      "Epoch [46/300], Loss: 0.5691, Accuracy: 0.8052\n",
      "Epoch [47/300], Loss: 0.5180, Accuracy: 0.8169\n",
      "Epoch [48/300], Loss: 0.4448, Accuracy: 0.8408\n",
      "Epoch [49/300], Loss: 0.5316, Accuracy: 0.8154\n",
      "Epoch [50/300], Loss: 0.5310, Accuracy: 0.8147\n",
      "Epoch [51/300], Loss: 0.5248, Accuracy: 0.8140\n",
      "Epoch [52/300], Loss: 0.5584, Accuracy: 0.8074\n",
      "Epoch [53/300], Loss: 0.5182, Accuracy: 0.8132\n",
      "Epoch [54/300], Loss: 0.5513, Accuracy: 0.8118\n",
      "Epoch [55/300], Loss: 0.5273, Accuracy: 0.8190\n",
      "Epoch [56/300], Loss: 0.4871, Accuracy: 0.8372\n",
      "Epoch [57/300], Loss: 0.4999, Accuracy: 0.8147\n",
      "Epoch [58/300], Loss: 0.5361, Accuracy: 0.8147\n",
      "Epoch [59/300], Loss: 0.4769, Accuracy: 0.8314\n",
      "Epoch [60/300], Loss: 0.5425, Accuracy: 0.8125\n",
      "Epoch [61/300], Loss: 0.5156, Accuracy: 0.8278\n",
      "Epoch [62/300], Loss: 0.4998, Accuracy: 0.8190\n",
      "Epoch [63/300], Loss: 0.5022, Accuracy: 0.8379\n",
      "Epoch [64/300], Loss: 0.5574, Accuracy: 0.8081\n",
      "Epoch [65/300], Loss: 0.5270, Accuracy: 0.8205\n",
      "Epoch [66/300], Loss: 0.5711, Accuracy: 0.7980\n",
      "Epoch [67/300], Loss: 0.5163, Accuracy: 0.8198\n",
      "Epoch [68/300], Loss: 0.5162, Accuracy: 0.8234\n",
      "Epoch [69/300], Loss: 0.5353, Accuracy: 0.8249\n",
      "Epoch [70/300], Loss: 0.5316, Accuracy: 0.8241\n",
      "Epoch [71/300], Loss: 0.4774, Accuracy: 0.8365\n",
      "Epoch [72/300], Loss: 0.4944, Accuracy: 0.8394\n",
      "Epoch [73/300], Loss: 0.4969, Accuracy: 0.8241\n",
      "Epoch [74/300], Loss: 0.5297, Accuracy: 0.8190\n",
      "Epoch [75/300], Loss: 0.4987, Accuracy: 0.8358\n",
      "Epoch [76/300], Loss: 0.5356, Accuracy: 0.8132\n",
      "Epoch [77/300], Loss: 0.5267, Accuracy: 0.8307\n",
      "Epoch [78/300], Loss: 0.5073, Accuracy: 0.8256\n",
      "Epoch [79/300], Loss: 0.5316, Accuracy: 0.8067\n",
      "Epoch [80/300], Loss: 0.5353, Accuracy: 0.8132\n",
      "Epoch [81/300], Loss: 0.5018, Accuracy: 0.8299\n",
      "Epoch [82/300], Loss: 0.5532, Accuracy: 0.8190\n",
      "Epoch [83/300], Loss: 0.5197, Accuracy: 0.8176\n",
      "Epoch [84/300], Loss: 0.5141, Accuracy: 0.8234\n",
      "Epoch [85/300], Loss: 0.5007, Accuracy: 0.8169\n",
      "Epoch [86/300], Loss: 0.4725, Accuracy: 0.8263\n",
      "Epoch [87/300], Loss: 0.4666, Accuracy: 0.8379\n",
      "Epoch [88/300], Loss: 0.5509, Accuracy: 0.8125\n",
      "Epoch [89/300], Loss: 0.4985, Accuracy: 0.8241\n",
      "Epoch [90/300], Loss: 0.5592, Accuracy: 0.8103\n",
      "Epoch [91/300], Loss: 0.4767, Accuracy: 0.8372\n",
      "Epoch [92/300], Loss: 0.5383, Accuracy: 0.8154\n",
      "Epoch [93/300], Loss: 0.5145, Accuracy: 0.8227\n",
      "Epoch [94/300], Loss: 0.4747, Accuracy: 0.8416\n",
      "Epoch [95/300], Loss: 0.4827, Accuracy: 0.8307\n",
      "Epoch [96/300], Loss: 0.4770, Accuracy: 0.8328\n",
      "Epoch [97/300], Loss: 0.4665, Accuracy: 0.8401\n",
      "Epoch [98/300], Loss: 0.4707, Accuracy: 0.8227\n",
      "Epoch [99/300], Loss: 0.5033, Accuracy: 0.8285\n",
      "Epoch [100/300], Loss: 0.4708, Accuracy: 0.8314\n",
      "Epoch [101/300], Loss: 0.4916, Accuracy: 0.8358\n",
      "Epoch [102/300], Loss: 0.4743, Accuracy: 0.8292\n",
      "Epoch [103/300], Loss: 0.4400, Accuracy: 0.8510\n",
      "Epoch [104/300], Loss: 0.4768, Accuracy: 0.8321\n",
      "Epoch [105/300], Loss: 0.5061, Accuracy: 0.8292\n",
      "Epoch [106/300], Loss: 0.4715, Accuracy: 0.8445\n",
      "Epoch [107/300], Loss: 0.5273, Accuracy: 0.8227\n",
      "Epoch [108/300], Loss: 0.5057, Accuracy: 0.8234\n",
      "Epoch [109/300], Loss: 0.4816, Accuracy: 0.8328\n",
      "Epoch [110/300], Loss: 0.4962, Accuracy: 0.8307\n",
      "Epoch [111/300], Loss: 0.4674, Accuracy: 0.8343\n",
      "Epoch [112/300], Loss: 0.4852, Accuracy: 0.8328\n",
      "Epoch [113/300], Loss: 0.4887, Accuracy: 0.8307\n",
      "Epoch [114/300], Loss: 0.4806, Accuracy: 0.8292\n",
      "Epoch [115/300], Loss: 0.5086, Accuracy: 0.8321\n",
      "Epoch [116/300], Loss: 0.4929, Accuracy: 0.8314\n",
      "Epoch [117/300], Loss: 0.5029, Accuracy: 0.8190\n",
      "Epoch [118/300], Loss: 0.4987, Accuracy: 0.8270\n",
      "Epoch [119/300], Loss: 0.5078, Accuracy: 0.8278\n",
      "Epoch [120/300], Loss: 0.4851, Accuracy: 0.8350\n",
      "Epoch [121/300], Loss: 0.4669, Accuracy: 0.8285\n",
      "Epoch [122/300], Loss: 0.4846, Accuracy: 0.8299\n",
      "Epoch [123/300], Loss: 0.4367, Accuracy: 0.8496\n",
      "Epoch [124/300], Loss: 0.4452, Accuracy: 0.8488\n",
      "Epoch [125/300], Loss: 0.4962, Accuracy: 0.8328\n",
      "Epoch [126/300], Loss: 0.4608, Accuracy: 0.8394\n",
      "Epoch [127/300], Loss: 0.4888, Accuracy: 0.8256\n",
      "Epoch [128/300], Loss: 0.4916, Accuracy: 0.8307\n",
      "Epoch [129/300], Loss: 0.4833, Accuracy: 0.8379\n",
      "Epoch [130/300], Loss: 0.4983, Accuracy: 0.8372\n",
      "Epoch [131/300], Loss: 0.4736, Accuracy: 0.8321\n",
      "Epoch [132/300], Loss: 0.4724, Accuracy: 0.8387\n",
      "Epoch [133/300], Loss: 0.4508, Accuracy: 0.8430\n",
      "Epoch [134/300], Loss: 0.4805, Accuracy: 0.8372\n",
      "Epoch [135/300], Loss: 0.4511, Accuracy: 0.8358\n",
      "Epoch [136/300], Loss: 0.4719, Accuracy: 0.8336\n",
      "Epoch [137/300], Loss: 0.4457, Accuracy: 0.8394\n",
      "Epoch [138/300], Loss: 0.4139, Accuracy: 0.8576\n",
      "Epoch [139/300], Loss: 0.4577, Accuracy: 0.8430\n",
      "Epoch [140/300], Loss: 0.5220, Accuracy: 0.8234\n",
      "Epoch [141/300], Loss: 0.4980, Accuracy: 0.8241\n",
      "Epoch [142/300], Loss: 0.4709, Accuracy: 0.8270\n",
      "Epoch [143/300], Loss: 0.5057, Accuracy: 0.8154\n",
      "Epoch [144/300], Loss: 0.5263, Accuracy: 0.8183\n",
      "Epoch [145/300], Loss: 0.4679, Accuracy: 0.8336\n",
      "Epoch [146/300], Loss: 0.4405, Accuracy: 0.8372\n",
      "Epoch [147/300], Loss: 0.4578, Accuracy: 0.8379\n",
      "Epoch [148/300], Loss: 0.4579, Accuracy: 0.8532\n",
      "Epoch [149/300], Loss: 0.4452, Accuracy: 0.8467\n",
      "Epoch [150/300], Loss: 0.4543, Accuracy: 0.8496\n",
      "Epoch [151/300], Loss: 0.4454, Accuracy: 0.8481\n",
      "Epoch [152/300], Loss: 0.4352, Accuracy: 0.8510\n",
      "Epoch [153/300], Loss: 0.4178, Accuracy: 0.8539\n",
      "Epoch [154/300], Loss: 0.4421, Accuracy: 0.8474\n",
      "Epoch [155/300], Loss: 0.4846, Accuracy: 0.8358\n",
      "Epoch [156/300], Loss: 0.4380, Accuracy: 0.8438\n",
      "Epoch [157/300], Loss: 0.4563, Accuracy: 0.8408\n",
      "Epoch [158/300], Loss: 0.4900, Accuracy: 0.8321\n",
      "Epoch [159/300], Loss: 0.4548, Accuracy: 0.8387\n",
      "Epoch [160/300], Loss: 0.4461, Accuracy: 0.8372\n",
      "Epoch [161/300], Loss: 0.4422, Accuracy: 0.8496\n",
      "Epoch [162/300], Loss: 0.4501, Accuracy: 0.8350\n",
      "Epoch [163/300], Loss: 0.4501, Accuracy: 0.8438\n",
      "Epoch [164/300], Loss: 0.5117, Accuracy: 0.8227\n",
      "Epoch [165/300], Loss: 0.4556, Accuracy: 0.8467\n",
      "Epoch [166/300], Loss: 0.4590, Accuracy: 0.8365\n",
      "Epoch [167/300], Loss: 0.4376, Accuracy: 0.8496\n",
      "Epoch [168/300], Loss: 0.4630, Accuracy: 0.8278\n",
      "Epoch [169/300], Loss: 0.4846, Accuracy: 0.8328\n",
      "Epoch [170/300], Loss: 0.4433, Accuracy: 0.8510\n",
      "Epoch [171/300], Loss: 0.4622, Accuracy: 0.8401\n",
      "Epoch [172/300], Loss: 0.4757, Accuracy: 0.8358\n",
      "Epoch [173/300], Loss: 0.4836, Accuracy: 0.8285\n",
      "Epoch [174/300], Loss: 0.4519, Accuracy: 0.8445\n",
      "Epoch [175/300], Loss: 0.4758, Accuracy: 0.8299\n",
      "Epoch [176/300], Loss: 0.4851, Accuracy: 0.8321\n",
      "Epoch [177/300], Loss: 0.4563, Accuracy: 0.8372\n",
      "Epoch [178/300], Loss: 0.4628, Accuracy: 0.8321\n",
      "Epoch [179/300], Loss: 0.4420, Accuracy: 0.8394\n",
      "Epoch [180/300], Loss: 0.4801, Accuracy: 0.8292\n",
      "Epoch [181/300], Loss: 0.4641, Accuracy: 0.8336\n",
      "Epoch [182/300], Loss: 0.4459, Accuracy: 0.8481\n",
      "Epoch [183/300], Loss: 0.4281, Accuracy: 0.8554\n",
      "Epoch [184/300], Loss: 0.4499, Accuracy: 0.8503\n",
      "Epoch [185/300], Loss: 0.3999, Accuracy: 0.8641\n",
      "Epoch [186/300], Loss: 0.4595, Accuracy: 0.8372\n",
      "Epoch [187/300], Loss: 0.4322, Accuracy: 0.8496\n",
      "Epoch [188/300], Loss: 0.4513, Accuracy: 0.8430\n",
      "Epoch [189/300], Loss: 0.4377, Accuracy: 0.8539\n",
      "Epoch [190/300], Loss: 0.4458, Accuracy: 0.8430\n",
      "Epoch [191/300], Loss: 0.4280, Accuracy: 0.8452\n",
      "Epoch [192/300], Loss: 0.4670, Accuracy: 0.8350\n",
      "Epoch [193/300], Loss: 0.4378, Accuracy: 0.8510\n",
      "Epoch [194/300], Loss: 0.4368, Accuracy: 0.8416\n",
      "Epoch [195/300], Loss: 0.4422, Accuracy: 0.8474\n",
      "Epoch [196/300], Loss: 0.4471, Accuracy: 0.8430\n",
      "Epoch [197/300], Loss: 0.4840, Accuracy: 0.8336\n",
      "Epoch [198/300], Loss: 0.4166, Accuracy: 0.8467\n",
      "Epoch [199/300], Loss: 0.4081, Accuracy: 0.8626\n",
      "Epoch [200/300], Loss: 0.4075, Accuracy: 0.8583\n",
      "Epoch [201/300], Loss: 0.4435, Accuracy: 0.8459\n",
      "Epoch [202/300], Loss: 0.4557, Accuracy: 0.8408\n",
      "Epoch [203/300], Loss: 0.4320, Accuracy: 0.8539\n",
      "Epoch [204/300], Loss: 0.4635, Accuracy: 0.8503\n",
      "Epoch [205/300], Loss: 0.4563, Accuracy: 0.8430\n",
      "Epoch [206/300], Loss: 0.4889, Accuracy: 0.8249\n",
      "Epoch [207/300], Loss: 0.4283, Accuracy: 0.8459\n",
      "Epoch [208/300], Loss: 0.4338, Accuracy: 0.8532\n",
      "Epoch [209/300], Loss: 0.4642, Accuracy: 0.8350\n",
      "Epoch [210/300], Loss: 0.4334, Accuracy: 0.8576\n",
      "Epoch [211/300], Loss: 0.4510, Accuracy: 0.8503\n",
      "Epoch [212/300], Loss: 0.4206, Accuracy: 0.8525\n",
      "Epoch [213/300], Loss: 0.4297, Accuracy: 0.8452\n",
      "Epoch [214/300], Loss: 0.4629, Accuracy: 0.8365\n",
      "Epoch [215/300], Loss: 0.4311, Accuracy: 0.8619\n",
      "Epoch [216/300], Loss: 0.4790, Accuracy: 0.8372\n",
      "Epoch [217/300], Loss: 0.4684, Accuracy: 0.8394\n",
      "Epoch [218/300], Loss: 0.4181, Accuracy: 0.8503\n",
      "Epoch [219/300], Loss: 0.4292, Accuracy: 0.8539\n",
      "Epoch [220/300], Loss: 0.4986, Accuracy: 0.8278\n",
      "Epoch [221/300], Loss: 0.4790, Accuracy: 0.8438\n",
      "Epoch [222/300], Loss: 0.4755, Accuracy: 0.8430\n",
      "Epoch [223/300], Loss: 0.4402, Accuracy: 0.8525\n",
      "Epoch [224/300], Loss: 0.4695, Accuracy: 0.8387\n",
      "Epoch [225/300], Loss: 0.4139, Accuracy: 0.8525\n",
      "Epoch [226/300], Loss: 0.4734, Accuracy: 0.8321\n",
      "Epoch [227/300], Loss: 0.4245, Accuracy: 0.8438\n",
      "Epoch [228/300], Loss: 0.4444, Accuracy: 0.8423\n",
      "Epoch [229/300], Loss: 0.4870, Accuracy: 0.8307\n",
      "Epoch [230/300], Loss: 0.4641, Accuracy: 0.8416\n",
      "Epoch [231/300], Loss: 0.4309, Accuracy: 0.8539\n",
      "Epoch [232/300], Loss: 0.4472, Accuracy: 0.8459\n",
      "Epoch [233/300], Loss: 0.4372, Accuracy: 0.8488\n",
      "Epoch [234/300], Loss: 0.4323, Accuracy: 0.8510\n",
      "Epoch [235/300], Loss: 0.4586, Accuracy: 0.8416\n",
      "Epoch [236/300], Loss: 0.4679, Accuracy: 0.8249\n",
      "Epoch [237/300], Loss: 0.4466, Accuracy: 0.8547\n",
      "Epoch [238/300], Loss: 0.4477, Accuracy: 0.8503\n",
      "Epoch [239/300], Loss: 0.4564, Accuracy: 0.8488\n",
      "Epoch [240/300], Loss: 0.4411, Accuracy: 0.8561\n",
      "Epoch [241/300], Loss: 0.4413, Accuracy: 0.8510\n",
      "Epoch [242/300], Loss: 0.4381, Accuracy: 0.8503\n",
      "Epoch [243/300], Loss: 0.4472, Accuracy: 0.8445\n",
      "Epoch [244/300], Loss: 0.4545, Accuracy: 0.8481\n",
      "Epoch [245/300], Loss: 0.4229, Accuracy: 0.8532\n",
      "Epoch [246/300], Loss: 0.4450, Accuracy: 0.8467\n",
      "Epoch [247/300], Loss: 0.4573, Accuracy: 0.8459\n",
      "Epoch [248/300], Loss: 0.4463, Accuracy: 0.8481\n",
      "Epoch [249/300], Loss: 0.4384, Accuracy: 0.8503\n",
      "Epoch [250/300], Loss: 0.4285, Accuracy: 0.8525\n",
      "Epoch [251/300], Loss: 0.4529, Accuracy: 0.8510\n",
      "Epoch [252/300], Loss: 0.4163, Accuracy: 0.8554\n",
      "Epoch [253/300], Loss: 0.4076, Accuracy: 0.8525\n",
      "Epoch [254/300], Loss: 0.4347, Accuracy: 0.8561\n",
      "Epoch [255/300], Loss: 0.4258, Accuracy: 0.8488\n",
      "Epoch [256/300], Loss: 0.4327, Accuracy: 0.8452\n",
      "Epoch [257/300], Loss: 0.4363, Accuracy: 0.8503\n",
      "Epoch [258/300], Loss: 0.4467, Accuracy: 0.8503\n",
      "Epoch [259/300], Loss: 0.4590, Accuracy: 0.8459\n",
      "Epoch [260/300], Loss: 0.4667, Accuracy: 0.8358\n",
      "Epoch [261/300], Loss: 0.4834, Accuracy: 0.8387\n",
      "Epoch [262/300], Loss: 0.4862, Accuracy: 0.8416\n",
      "Epoch [263/300], Loss: 0.4323, Accuracy: 0.8488\n",
      "Epoch [264/300], Loss: 0.4208, Accuracy: 0.8539\n",
      "Epoch [265/300], Loss: 0.4429, Accuracy: 0.8525\n",
      "Epoch [266/300], Loss: 0.4424, Accuracy: 0.8481\n",
      "Epoch [267/300], Loss: 0.4423, Accuracy: 0.8539\n",
      "Epoch [268/300], Loss: 0.4558, Accuracy: 0.8496\n",
      "Epoch [269/300], Loss: 0.4459, Accuracy: 0.8467\n",
      "Epoch [270/300], Loss: 0.4473, Accuracy: 0.8554\n",
      "Epoch [271/300], Loss: 0.4549, Accuracy: 0.8416\n",
      "Epoch [272/300], Loss: 0.4324, Accuracy: 0.8554\n",
      "Epoch [273/300], Loss: 0.4599, Accuracy: 0.8430\n",
      "Epoch [274/300], Loss: 0.4607, Accuracy: 0.8387\n",
      "Epoch [275/300], Loss: 0.4698, Accuracy: 0.8358\n",
      "Epoch [276/300], Loss: 0.4747, Accuracy: 0.8299\n",
      "Epoch [277/300], Loss: 0.4284, Accuracy: 0.8394\n",
      "Epoch [278/300], Loss: 0.4091, Accuracy: 0.8605\n",
      "Epoch [279/300], Loss: 0.4280, Accuracy: 0.8525\n",
      "Epoch [280/300], Loss: 0.4362, Accuracy: 0.8488\n",
      "Epoch [281/300], Loss: 0.4545, Accuracy: 0.8452\n",
      "Epoch [282/300], Loss: 0.4486, Accuracy: 0.8372\n",
      "Epoch [283/300], Loss: 0.4222, Accuracy: 0.8488\n",
      "Epoch [284/300], Loss: 0.4127, Accuracy: 0.8554\n",
      "Epoch [285/300], Loss: 0.4625, Accuracy: 0.8314\n",
      "Epoch [286/300], Loss: 0.4799, Accuracy: 0.8321\n",
      "Epoch [287/300], Loss: 0.3988, Accuracy: 0.8648\n",
      "Epoch [288/300], Loss: 0.4487, Accuracy: 0.8438\n",
      "Epoch [289/300], Loss: 0.4509, Accuracy: 0.8445\n",
      "Epoch [290/300], Loss: 0.4186, Accuracy: 0.8525\n",
      "Epoch [291/300], Loss: 0.4450, Accuracy: 0.8590\n",
      "Epoch [292/300], Loss: 0.4702, Accuracy: 0.8379\n",
      "Epoch [293/300], Loss: 0.4364, Accuracy: 0.8532\n",
      "Epoch [294/300], Loss: 0.4146, Accuracy: 0.8597\n",
      "Epoch [295/300], Loss: 0.3827, Accuracy: 0.8699\n",
      "Epoch [296/300], Loss: 0.4431, Accuracy: 0.8467\n",
      "Epoch [297/300], Loss: 0.4740, Accuracy: 0.8307\n",
      "Epoch [298/300], Loss: 0.4136, Accuracy: 0.8554\n",
      "Epoch [299/300], Loss: 0.4405, Accuracy: 0.8467\n",
      "Epoch [300/300], Loss: 0.4131, Accuracy: 0.8474\n"
     ]
    }
   ],
   "source": [
    "train(BASE, criterion, optimizer, train_loader, num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e10dc0d-ec17-4106-92d1-570c9b244e21",
   "metadata": {},
   "source": [
    "### Validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e3ed36ec-5632-4834-b99c-87b384b22e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, criterion, X,y):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X)\n",
    "        t_loss = criterion(outputs, y)\n",
    "        t_accuracy = calculate_accuracy(outputs, y)\n",
    "        \n",
    "\n",
    "    print(f'Test Loss: {t_loss:.4f}, Test Accuracy: {t_accuracy:.4f}')\n",
    "    return t_loss, t_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c1749099-9e43-4e05-8111-400df89ef94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.8371, Test Accuracy: 0.6003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(2.8371), 0.6003005259203607)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(BASE, criterion, torch.tensor(x_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d2c35-858c-444d-b311-cf55f17ce504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
